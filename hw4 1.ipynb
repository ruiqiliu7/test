{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NxFvGa01e7DA",
        "outputId": "3f8f353c-d072-4163-ead6-0b3086ff4270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/homebrew/lib/python3.11/site-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (1.26.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.21.4)\n",
            "Requirement already satisfied: packaging in /Users/yangyang/Library/Python/3.11/lib/python/site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yangyang/Library/Python/3.11/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /Users/yangyang/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install datasets\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "yelp_data_set = load_dataset(\"yelp_review_full\")\n",
        "\n",
        "# Split into training data\n",
        "train_data = yelp_data_set['train']\n",
        "test_data = yelp_data_set['test']\n",
        "\n",
        "# Convert training data to pandas DataFrame\n",
        "train_df = pd.DataFrame(train_data)\n",
        "test_df = pd.DataFrame(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of training data: 650000\n",
            "Size of test data: 50000\n",
            "   label                                               text\n",
            "0      4  dr. goldberg offers everything i look for in a...\n",
            "1      1  Unfortunately, the frustration of being Dr. Go...\n",
            "2      3  Been going to Dr. Goldberg for over 10 years. ...\n",
            "3      3  Got a letter in the mail last week that said D...\n",
            "4      0  I don't know what Dr. Goldberg was like before...\n"
          ]
        }
      ],
      "source": [
        "# Get the size of train_data and test_data\n",
        "train_size = len(train_data)\n",
        "test_size = len(test_data)\n",
        "\n",
        "print(\"Size of training data:\", train_size)\n",
        "print(\"Size of test data:\", test_size)\n",
        "\n",
        "\n",
        "# Print out the first 5 rows of the DataFrame\n",
        "print(train_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oidhKgu8hML5",
        "outputId": "6923f00c-6ca5-461c-a119-9a10e4c78c72"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Adding a new column for review length\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_df[\u001b[39m'\u001b[39m\u001b[39mreview_length\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Plotting the distribution of review lengths\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4898\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4899\u001b[0m         func,\n\u001b[1;32m   4900\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4901\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4902\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4903\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4904\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
            "File \u001b[0;32mlib.pyx:2981\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mlib.pyx:2543\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/numpy/core/numeric.py:274\u001b[0m, in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_full_dispatcher\u001b[39m(shape, fill_value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, like\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    271\u001b[0m     \u001b[39mreturn\u001b[39;00m(like,)\n\u001b[0;32m--> 274\u001b[0m \u001b[39m@set_array_function_like_doc\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfull\u001b[39m(shape, fill_value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m, like\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    277\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39m    Return a new array of given shape and type, filled with `fill_value`.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m like \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the distribution of ratings\n",
        "train_df['label'].value_counts().sort_index().plot(kind='bar')\n",
        "plt.title('Distribution of Yelp Review Ratings')\n",
        "plt.xlabel('Ratings (1 star to 5 stars)')\n",
        "plt.ylabel('Number of Reviews')\n",
        "plt.xticks(rotation=0)  # Keeps the labels horizontal\n",
        "plt.show()\n",
        "\n",
        "# Adding a new column for review length\n",
        "train_df['review_length'] = train_df['text'].apply(len)\n",
        "\n",
        "# Plotting the distribution of review lengths\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(train_df['review_length'], bins=50, color='blue', alpha=0.7)\n",
        "plt.title('Distribution of Review Lengths')\n",
        "plt.xlabel('Length of Reviews')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Displaying examples of reviews for each rating\n",
        "for label in sorted(train_df['label'].unique()):\n",
        "    sample_review = train_df[train_df['label'] == label].iloc[0]\n",
        "    print(f\"Rating: {label} stars\\nReview: {sample_review['text']}\\n\" + \"-\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label                                               text\n",
            "0      2  Kabuto is your run-of-the-mill Japanese Steakh...\n",
            "1      4  Visiting here for 10 days and staying in a con...\n",
            "2      1                             Terrible terrible food\n",
            "3      4  This is a beautiful theatre with a gorgeous gl...\n",
            "4      3  I don't quite get this place or why Asians lov...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Shuffle the test dataset\n",
        "shuffled_test_data = test_data.shuffle(seed=42)  # You can adjust the seed value for reproducibility\n",
        "\n",
        "# Take a sample from the shuffled test data\n",
        "sampled_test_data = shuffled_test_data[:500]  # Adjust the slice to the desired sample size\n",
        "sampled_test_df = pd.DataFrame(sampled_test_data)\n",
        "# sampled_test_df = sampled_test_df[sampled_test_df['label'] != 3] \n",
        "\n",
        "print(sampled_test_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    max_token_limit = 512\n",
        "    # min_token_limit = 40\n",
        "    if len(text) > max_token_limit:\n",
        "        return text[:512]\n",
        "    else:\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "63dfd85fc4064215b20fc35217ff313c",
            "f11bb9e9370a403bbe639be12f6703b9",
            "648f875e21d84549a47dfbe95e51ac47",
            "ee22eeec775545ce897642c2b62edea2",
            "6b610b456e81425485e100c1ecac371c",
            "37629a02aa1d4d72bd24bfa1c0a30918",
            "324ac8fa62894f75aef9ccaeb6159938",
            "e817cf68f93142bfb356ce2478c10ab2",
            "e4a44ad925d1462298b9004f2e58eda4",
            "cabbc666f18a4ee8bfd6bf7be7863450",
            "81218cae9b114deda5efe67ebccd4ffa",
            "e5a944b5ea9d45a0942502e0900cbf0f",
            "b69128b2082a4a52b3be4aa440c41d74",
            "cf33926ec7b84d5b866859868c56b0e1",
            "5696db505896423abac4bc785e6fce9c",
            "f13d4ebadc8f4b60bf35c2e03a874161",
            "7fb3c099243648c39ce21e89d263108b",
            "089c8f0ba9354a7bb2dbc41634ac7d27",
            "e8f4b4c6fe80481b8766d2414a201cd3",
            "4c084639238a45a9a4586a0b05283e1b",
            "823fad1bda224288bc6786e3ea4179a1",
            "72db37f4834d4c1fa50ad7b249732b70",
            "f062f290acf04744b36cc4c92be6809b",
            "56ad8bfdcb1a45c2a65352c8a499eef5",
            "02d2aed797dc441483d8803d8d74f6db",
            "bee4c831970845eb92d8c6471d4b8557",
            "89f415836ab440bdb84300fa5a09981c",
            "683e085695ae4a05a40e70bc85159fe3",
            "3e45ae9fb3d84202a6fcfd3317499f1d",
            "30a98ee1f2984431bc317acd113a1fca",
            "f57e89cb93fe4966883324e21c524829",
            "dd2fff18a17c448c8b8b4fcf341c5304",
            "568c73553b8648d4b74391b87838a76d",
            "a902df1d223f41d39fb09016c95d5e02",
            "fcf8afc483284445966ba610e6d06619",
            "73061ad5f1c24d3284d5f4890a1cf1c4",
            "8122605946c64cf1b80e18da16b62d1c",
            "8c79d5c615fd4f2f84a73e14a8700eb6",
            "895bdab903f143fab9075ab9b769d8ab",
            "344b21f271114f6aa3e956a1dfaefe38",
            "7da1e2c25eb5448e9dc757c98d6539a2",
            "44325d6b91764d67a7f90c68aced716f",
            "51536207c7c143258398fd03787ec2f5",
            "2bd73e17a8ef48b6a0063b153d9006c6",
            "10a155879a0e4d33abc9c2c4951c0c3f",
            "927b5da4fc524ddd90dd200919210b25",
            "9bc31f6b126a4483be56f2d083fc6760",
            "1b6fd4e2b17b4535b58dc6482f1ff9ca",
            "a1cff6262f4c43bd9b626f40d53fe3ef",
            "1036bff4d8c148f8890d7183283f28e7",
            "e3dddd82bf5648ec8eba1caf1b5547e3",
            "0e7cb24f6ae44433994b2f70bb1a89dd",
            "a6a177d7a89f41abbfbf2ea5906c9e31",
            "3802c5b12e834eb39cf316c2700c879c",
            "579e5a8a96c246cdb941335f82a52fb8"
          ]
        },
        "id": "0kbpJHmAijV5",
        "outputId": "7d0c3fe6-2200-49ed-92b9-3adf279e117c"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load pipelines for each model\n",
        "pipeline_1 = pipeline(task='sentiment-analysis', model='gilf/english-yelp-sentiment')\n",
        "\n",
        "def perform_sentiment_analysis_1(text):\n",
        "    sentiment_prediction = pipeline_1(preprocess_text(text))[0]\n",
        "    sentiment_prediction_label = int(sentiment_prediction['label'][:1])-1\n",
        "    sentiment_prediction_score=sentiment_prediction['score']\n",
        "    return [sentiment_prediction_label, sentiment_prediction_score]\n",
        "\n",
        "predictions_df = pd.DataFrame({'actual_score': sampled_test_df['label'], 'text': sampled_test_df['text']})\n",
        "\n",
        "predictions_df[['prediction_label','prediction_score']] = sampled_test_df['text'].apply(perform_sentiment_analysis_1).apply(pd.Series)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.666\n"
          ]
        }
      ],
      "source": [
        "accuracy_1 = accuracy_score(predictions_df['actual_score'], predictions_df['prediction_label'])\n",
        "print(accuracy_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[73 13  0  2  0]\n",
            " [35 77 14  0  0]\n",
            " [ 2 18 57  8  2]\n",
            " [ 0  3 20 70 28]\n",
            " [ 0  1  1 20 56]]\n",
            "Text for false negative results:\n",
            "prediction:  0.0  actual:  3\n",
            "Was in conference at the Phoenix Convention Center and a glorious smell wafted through from the east. Turning to my left I saw a plate, and lady tearing something up..fiercely . Me and three other people immediately stopped what we were doing and walked somewhat zombie like to where the food was and asked...where did you get that? Karim's Cobbler Shop and Deli was her reply...in between bites.  \\n\\nNow I've been in Phoenix for 3 months looking for a taste of soul food. And here it was in my back yard! I was shocked!!!\\n\\nWith a sense of urgency I walked the streets until once again I was seduced by the smell of fried fish. Wasnt very far, and it was perched right in front of the Light Rail.  My kind of place.\\n\\nFirst thought, very humble. Very clean and neat and humble.  The owner was very kind, friendly and humble. Very confident that whatever I ordered I would love it. And I did.\\n\\nAs the only customer in the place I had soo many questions..How long were you here. Where do you market you store, cuz I never heard of it. With a smile he explained that his customers usually come in thru word of mouth and via the smell.\\n\\nI ordered the 3 piece whiting (its a east coast thing) It was well seasoned yet  non-greasy and well I wanted more of it. A side of red rice and beans which was flavorful and simply not enough.  Not usually a peach cobbler fan but it had so many intricate flavors. I sensed some clove, cinnamon, brown sugar...and something I can't quite put my finger on. The detective will be back to figure out this mystery.  It was sooo GOOOD!\\n\\n\\nHearing so many complaints that Phoenix has alot of sun but no soul I can confidently say that there is however scatter amongst the desert.  One just have to put in the detective work. Use the senses...it will lead you there. But if you can't follow my lead.  Karim's Cobbler shop is the place to get your grub on.  Bring your families and friends too.  Everyone will leave happy. Or with an extra side :)\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "Heute noch mal dagewesen und darum gebeten keinen Geschmacksverst\\u00e4rker zu verwenden, was auch ohne murren umgesetzt wurde. Der Reis hat dennoch sehr gut geschmeckt.\\n\\nAlso mein Tipp: Guter Laden, allerdings sollte man ausdr\\u00fccklich ohne den Geschmacksbooster bestellen.\n",
            "\n",
            "\n",
            "\n",
            "Text for false positive results:\n",
            "prediction:  3.0  actual:  1\n",
            "Wow. Now I remember why I never cared much for Butterfield's. We had a good experience about a month ago, motivating us to return. Today, our experience could best be described as stressful.\\n\\nWe checked in early on a Sunday, largely beating the rush. As a party of six, however, we still had a 25 minute wait. Not bad. A half hour came and went, so we checked to see how much longer it would be. They indicated we had already been seated. Quite a surprise to us as you can imagine. \\n\\nWe were promised we would be next. Another 25 minutes came and went. Another large party was seated. Then, finally, us. Without apology. \\n\\nService was adequate. The specialty pancakes were fine, but two omelets we ordered were quite disappointing. \\n\\nA simple genuine apology for the seating screw up would have gone a long way. Or at least then serve us something exceptional.  Treating customers so poorly, whether a result of complacency or arrogance, is how seemingly invincible restaurants like Butterfield's find a path to failure.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "We just moved to MTL and he had never had a smoked meat! We were a bit lost and hungry and stumbled upon this Dunns location. The roomies had just has a great Dunns experience back home. So I decided this would be a great place to intro TJ to the smoked meat sandwich. I was wrong. We split the traditional medium smoked meat platter (sandwich, fries, coleslaw, and a pickle). Positives - enough food for two, the fries were good and plentiful, pickle was tasty. Negatives - a bit on the pricey side (~$15 for what is supposed to feed one person),  smoked meat was meh (dry, salty, overly processed). Overall it was ok but I'll have a hard time convince him to try smoked meat again.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "I happened to be in the University area recently around lunch time, so I quickly checked my Yelp App to see what dining options were nearby.  I found this place and decided to check it out.  When I pulled up in the parking lot, I had a bit of a dilemma as there was a Middle Eastern place right next door... but I decided to check out the Caribbean Hut since I have great Middle Eastern food in my neighborhood but no Caribbean/Jamaican places.  \\n\\nSo, I walked in and found that this place is one of those spots where you go up and place your order at the counter.  I quickly scanned the menu board and decided to go with jerk chicken. I asked and the girl behind the counter & she said it was served with beans & rice.  Ok - sounds good so far.  I wasn't sure about portion sizes, but I decided to go with the smaller portion size.  \\n\\nWhen my food came out, I was disappointed to see three little tiny pieces of chicken (which were mostly bone), rice  with only a couple of sparse beans mixed into the rice, and about half the plate was made up of some sort of slaw (WTH- she didn't tell me slaw came on the plate! I hate slaw, yuck!)  It did have 2 slices of plantains, which were tasty. \\n\\nWhen I dug into it, things didn't really get any better.  The jerk chicken was not very delicious - I was quite disappointed in both the subdued flavor and the terrible cut of \\\"meat\\\"...it was like 3 little chicken wings that hardly had any meat whatsoever on it.  Definitely not what I was expecting. \\n\\n I was expecting to dig  into a plate of wonderful calypso rice with  beans & a flavorful jerk chicken with plenty of spicy flavor. But this was just sad.  Based on the other reviews, maybe I just caught them on a bad day, but the experience was so disappointing that I probably won't be back.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  1\n",
            "Courtney's review is pretty much spot on. I can't think of a better way to describe the show other than Rick Thomas revels in himself. Between his magic tricks, he talks about how he followed his dreams and shows weird, outdated video segments about his life. Like the video of him doing the cha cha with his sister when he was 14 while the words \\\"You go boy!\\\" fly across the screen. ?? I came for magic and tigers, Rick. Not to see your weird home vids. Rick also repeats some crazy nonsense about dreams throughout the show. And I don't mean cutesy, Disney, 'follow your dreams' stuff. More like weird philosophical theories that make you say, \\\"wtf is he talking about?\\\" Also, the show tended to bob between the magic of childhood and him dry humping his sexy assistants on stage. All in all, it was pretty ridiculous and made my jaw drop several times. But I still had a great time with friends because we laughed about it long after the show ended.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# overall we can tell the modal did a pretty good job on \n",
        "conf_matrix = confusion_matrix(predictions_df['prediction_label'], predictions_df['actual_score'])\n",
        "print(conf_matrix)\n",
        "\n",
        "# Define TF and FT rows based on prediction score and actual score\n",
        "false_negative_rows = predictions_df[(predictions_df['prediction_label'] != predictions_df['actual_score']) & \n",
        "                          ((predictions_df['prediction_label'] == 0) | (predictions_df['prediction_label'] == 1)) & \n",
        "                          ((predictions_df['actual_score'] == 3) | (predictions_df['actual_score'] == 4))]\n",
        "\n",
        "false_positive_rows = predictions_df[(predictions_df['prediction_label'] != predictions_df['actual_score']) & \n",
        "                           ((predictions_df['prediction_label'] == 3) | (predictions_df['prediction_label'] == 4)) & \n",
        "                          ((predictions_df['actual_score'] == 0) | (predictions_df['actual_score'] == 1))]\n",
        "\n",
        "\n",
        "print(\"Text for false negative results:\")\n",
        "for idx, row in false_negative_rows.iterrows():\n",
        "    print('prediction: ', row['prediction_label'], ' actual: ', row['actual_score'])\n",
        "    print(row['text'])\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\"\\nText for false positive results:\")\n",
        "for idx, row in false_positive_rows.iterrows():\n",
        "    print('prediction: ', row['prediction_label'], ' actual: ', row['actual_score'])\n",
        "    print(row['text'])\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# analysis:\n",
        "#\n",
        "# false negative breakdown:\n",
        "#   - in another language, modal gave a 0 label\n",
        "#   - very very long text, ambigious whether it is positive or negative, modal gave 0, actual 3\n",
        "#\n",
        "# false positive breakdown:\n",
        "#   - modal gave mostly 3, one 4 on actual 1 reviews. \n",
        "#   - negative words like 'never' 'without' 'can't' might affected the prediction\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdl-lSJkhe-z",
        "outputId": "e2a5a904-bfa6-4fcf-8d3b-c48cafa37479"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Define a function to apply sentiment analysis over a batch of reviews\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"milyiyo/multi-minilm-finetuned-amazon-review\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"milyiyo/multi-minilm-finetuned-amazon-review\")\n",
        "pipeline_2 = pipeline(task='sentiment-analysis', model=model,tokenizer=tokenizer)\n",
        "\n",
        "def perform_sentiment_analysis_2(text):\n",
        "    sentiment_prediction = pipeline_2(preprocess_text(text))[0]\n",
        "    sentiment_prediction_label = int(sentiment_prediction['label'][6])\n",
        "    sentiment_prediction_score=sentiment_prediction['score']\n",
        "    return [sentiment_prediction_label, sentiment_prediction_score]\n",
        "\n",
        "\n",
        "predictions_2_df = pd.DataFrame({'actual_score': sampled_test_df['label'], 'text': sampled_test_df['text']})\n",
        "\n",
        "predictions_2_df[['prediction_label','prediction_score']] = sampled_test_df['text'].apply(perform_sentiment_analysis_2).apply(pd.Series)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.434\n",
            "Index(['actual_score', 'text', 'prediction_label', 'prediction_score'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "accuracy_2 = accuracy_score(predictions_2_df['actual_score'], predictions_2_df['prediction_label'])\n",
        "print(accuracy_2)\n",
        "\n",
        "print(predictions_2_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[50 20  5  4  3]\n",
            " [39 49 13  7  2]\n",
            " [16 30 33 15  5]\n",
            " [ 2  8 24 20 11]\n",
            " [ 3  5 17 54 65]]\n",
            "Text for false negative results:\n",
            "prediction:  1.0  actual:  3\n",
            "Enough variety for me. Only reason I go to buffet - Shrimp, Oysters, Sushi and Salmon. They had all of these, so I'm happy. If you are looking for a quality buffet, skip this one . It didn't look clean and I had my waitress sit on our side table facing us while we eat. Annoyed, but I don't care much. Total bill without drinks, with tax - $22.64. \\n\\nI will come back here again over Lin's. I won't bring guests here though!\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "I have only been to MADCAP once, to see \\\"Until the Light Takes Us\\\" - a documentary about KVLT Norwegian Black Metal. I am very excited to have a theater playing REAL independent films and cult classics nearby. I frequently visited Chandler Cinemas to see films put on by Midnight Movie Mamacita - Cannibal Holocaust, El Topo, The Holy Mountain, Re-animator, Black Christmas.. etc. I was very disappointed to see that theater go. When I found out that she'd been relocated to continue the tradition at MADCAP, I rejoiced. I look forward to seeing many movies here in the future.\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  3\n",
            "the arizona burger gets the extra star here- it's wonderfully spicy. other than that, it seems like big specialty burgers that are good but not great\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  4\n",
            "Just go walk down it. You'll see.\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  3\n",
            "I gave them 4 stars only because they are so new. Probably would be 3 stars but the staff was trying very hard. I think they should STOP, review talk about the pros and cons and have a good training day. Staff were confused on where food went and what table numbers were. You can't have staff walking around looking for who ordered what.\\nPOS the staff was using was phone size and they seemed to struggle with inputting the orders.\\nNow the food, we had a table of 4 and all had something different. Cod bites were good, as were the chicken skewers. I had the Meatloaf which I would give an A, very tasty and the mashed potatoes were perfectly seasoned for my taste.\\nAnother dish was the Chicken Noodles, not-so-good, had a very odd taste spices didn't seem to work.\\n3rd dish was the Salmon surf. Pretty hard to screw up Salmon but it was over salted, sorry.\\nLast dish was Fish Tacos. She had Cod tacos instead of Salmon and said she enjoyed it. She wished they offered Black beans with the tacos to make it more authentic, but enjoyed it.\\nDesert we had the Bread pudding. It was very good, not the best in town, but very good.\\n\\nLocation, Location, Location is one of the best in the Valley. I'm not sure why other restaurants have not made it there as it's a wonderful, beautiful location on the Lake in \\\"The Lakes\\\" community. Tons of space inside and on the outside patio, there's even a boat dock for the locals.\\nEntertainment.\\nThey had Live music on the Friday night we were there and they were good. They also have separate areas where you and your friends can play pool, throw darts, or play a little corn hole. Huge bar fully loaded makes it a place you could spend the evening.\\nWho was there?\\nSeemed like a nice mix of people young and old. Decor was very open, maybe even too much but I still liked it. View was amazing.\\n\\nI hope they take the suggestions of their critics good and bad as we'd really love to see this place succeed. With a little tweaking, this could be a place I visit often. We wish them the best of luck, we'll try again in a couple months to see how things progress.\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "They're in NDG now! \\nImagine the glee when we learned that TA was bringing its pies to Monkland Ave / Girouard!  Villa Maria is the closest Metro stop\\n\\nSo far the pies we've had (as take-out) are:\\n\\nSteak Bacon Cheese. Verdict = Delicious\\n\\nButter Chicken. Verdict = Oh, Yummy!\\n\\nSpinach, mushroom, tomato & ricotta. Verdict = Vegetarian pies, although tasty and possibly healthy are not the thing of which legends are made. \\n\\nNed Kelly. Verdict = OMG OMG OMG!\\nWhile you can easily imagine the first three pies flavour profile you're going to have to try the Ned Kelly. It's a steak pie, with fried egg and cheese and BBQ sauce all in one magical eye-popping pie! Serve any of these pies (except for the vile veggie one) alongside some mushy peas, mashed potatoes and and a cold one and you're golden.\\n\\nThey've got big pies to take home and they have little pies that you can eat while you're taking your big pie home. They've really thought of everything.\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  3\n",
            "On our recent trip to Vegas I researched different restaurants to try - turns out that Dos Caminos AND Isla have closed. We knew we'd be in the Cosmo for the Secret Pizza (that's another review) and I wanted to try China Poblano after reading the menu on the Cosmo website. What I DIDN'T do is check the Yelp! reviews, and I'm glad I didn't. What we experienced was so far different from most reviews that I've just read!\\nOK look - when you're on vacation, you tend to spend money. $15 drinks are the going price at upscale hotels. And the \\\"salt air margarita\\\" (I just HAD to try one) was worth every cent!  I have no idea how they do it - the salt cloud that floats on the surface of the drink stays there as you drink, so with every sip you get a piece of salt heaven. \\nThe wait staff were friendly and efficient. The manager, I\\u00f1igo, even stopped by to chat with K'ayum (age 8) and watched him do his latest magic trick.  We ordered queso fundido with chorizo. It came with fresh-made tortillas and was excellent. Adriana got a carnitas taco and she was thrilled with the chicharr\\u00f3n topping. I had a fish taco which was fantastic, and K'ayum had some noodles which he devoured (and he's a picky eater!). \\nThe drinks were what really got me excited. After the \\\"salt air margarita\\\" I had another specialty called a \\\"Mexican gin and tonic.\\\" It's made with cilantro, elderflower liqueur, and I don't know what else, but it worked. For dessert I had a tequila flight that came with house-made sangrita that was sublime!  I wish I had a bottle of their sangrita for sipping tequila here at home!\\nAnyway, it's a week later and we're still talking about our experience. We loved the decor, the ambiance, the service, the food, and the drinks. We'll be back!\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  4\n",
            "CLOSED!!!!\\n\\nIt is close to work, so I went back had a hot ham and cheese it was quite good and the service was much better.  Tried to go back again last week and it's closed.  No sign, emptied out.\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  3\n",
            "Why did I wait so long to try Dickey's?  \\n\\nMy husband and I visited Dickey's on Sunday afternoon for a late lunch. The smoked meats on the menu are pretty straight forward, pulled pork, beef brisket, sausage, ham, turkey and chicken - all hickory smoked in their onsite pits. Now, I know I'm in North Carolina where pulled pork is king, but I can't pass up brisket. I ordered a 1 meat plate with beef brisket. The plate comes with 2 sides and I chose the baked potato casserole and the fried onion tanglers.  Boy, did I choose right!  You get a hefty portion of meat with a soft roll with pickles and onions. You can also choose from a variety of sauces at the sauce bar.  My husband also got the brisket but got the jalapeno beans and fried okra.  He said he really liked his plate too.  The brisket was tender with a nice smokey flavor. I chose the original bbq sauce and it was the perfect accompaniment.  And to top it all off, everyone gets free soft-serve vanilla ice cream!  It's self serve and it was a great ending to a really great lunch!\\n\\nThe service was super, super nice and attentive. I've been plotting our next visit. We will definitely be back!  The bakers (stuffed baked potatoes) will be next on my list!\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  4\n",
            "This place is bomb!!! Love kimchi fried rice + 4 skewers!! HEAVEN!\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  4\n",
            "I went in to John Mario's a bit skeptical - you never know what you're going to get with any given hair salon. This was the first time I'd had my hair cut in Vegas, so I went completely off of online reviews (like this one). \\n\\nI requested a fairly challenging hair cut from my barber, Bill. I pulled up a photo of the style I liked on my phone and showed it to him. After studying it and talking it through with me, Bill went straight to work. Watching him work with the clippers was absolutely mesmerizing - you can tell the guy is a pro. I watched in awe as he shaped my raggedy mop into a style nearly identical to the photo I had showed him just 20 minutes earlier. The end result FAR exceeded my expectations! \\n\\nNeedless to say, I highly recommend John Mario's - especially Bill. He's as talented with a pair of scissors and clippers as I've seen, and he can absolutely create the exact look you want.\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "Was in conference at the Phoenix Convention Center and a glorious smell wafted through from the east. Turning to my left I saw a plate, and lady tearing something up..fiercely . Me and three other people immediately stopped what we were doing and walked somewhat zombie like to where the food was and asked...where did you get that? Karim's Cobbler Shop and Deli was her reply...in between bites.  \\n\\nNow I've been in Phoenix for 3 months looking for a taste of soul food. And here it was in my back yard! I was shocked!!!\\n\\nWith a sense of urgency I walked the streets until once again I was seduced by the smell of fried fish. Wasnt very far, and it was perched right in front of the Light Rail.  My kind of place.\\n\\nFirst thought, very humble. Very clean and neat and humble.  The owner was very kind, friendly and humble. Very confident that whatever I ordered I would love it. And I did.\\n\\nAs the only customer in the place I had soo many questions..How long were you here. Where do you market you store, cuz I never heard of it. With a smile he explained that his customers usually come in thru word of mouth and via the smell.\\n\\nI ordered the 3 piece whiting (its a east coast thing) It was well seasoned yet  non-greasy and well I wanted more of it. A side of red rice and beans which was flavorful and simply not enough.  Not usually a peach cobbler fan but it had so many intricate flavors. I sensed some clove, cinnamon, brown sugar...and something I can't quite put my finger on. The detective will be back to figure out this mystery.  It was sooo GOOOD!\\n\\n\\nHearing so many complaints that Phoenix has alot of sun but no soul I can confidently say that there is however scatter amongst the desert.  One just have to put in the detective work. Use the senses...it will lead you there. But if you can't follow my lead.  Karim's Cobbler shop is the place to get your grub on.  Bring your families and friends too.  Everyone will leave happy. Or with an extra side :)\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  4\n",
            "Bam!  That's how excited I am to write this review.  I've had Cafe Du Jour bookmarked \\\"To Try\\\" for over a year, and I'm angry I haven't come sooner.  We had one of our best dinners in the 'burgh the past two years.  \\n\\nIt was sold to me as a French Bistro - but it's really not.  None of the items are classic French comfort food, such as a coq au vin, duck confit, pate, or other type of items.  I think it falls in the New American cuisine.  Correction, it is delicious New American cuisine.  Soy-glazed meatballs ($10), pork, apple butter and brie crostini ($10), fennel rubbed pork chop with crispy kale($24), chicken breast stuffed with feta and spinach ($24), are some of the items that I can recall.\\n\\nThere isn't a website, and the menu you can find on allmenus seems to be a lunch menu, and outdated.  I wouldn't let that deter you at all - you just have to trust your fellow Yelpers who rave about this place.  I do disagree on the $$ designation.  Two people with 2 apps, 2 entrees, 1 desert, and a cork fee was $86 (and $100 adding tip).\\n\\nNow, it is small, or at least while the patio is closed.  8 tables or so, and only 4 staff it seemed.  One host/waiter/runner, one chef, one sous chef, and an extra hand.  The pace between our courses was a bit longer than usual, but it didn't really bother me like it usually does.  The staff is working hard, and you can see it, and the food is so good I didn't really care.  And as mentioned elsewhere, BYOB with $2/stem.\\n\\nThis restaurant needs to be the next place you go.\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "Too bad they're closed on sunday. Definitely better than mcdonalds. I love this place!\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  3\n",
            "Can never get enough! Please put more mushrooms on 4 dosen't cut it.\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  3\n",
            "We very much enjoyed our dinner here but will echo what another writer said, which is that the meal goes very fast...almost too fast.  I wish they would leave another minute or two between the courses just to give folks an opportunity to truly appreciate all the fine favors of the dishes.  The chefs move so fast and announce the dishes so quickly, that some of the meal felt like a blur.  \\n\\nThe only other suggestion I would have would be for them to do a bit more of the preparation in front of the diners instead of just the plating.  Some of the various processes they talked about sounded really interesting, but we didn't get to see that aspect of the preparation, which was a bit disappointing.  I expected that they would be cooking in front of us, not just preparing the final products.  \\n\\nOther than that, the food was spectacular and the service was outstanding.  When we asked questions about the various dishes, the chefs were more than willing to explain how the dishes were made.  I wish they gave more explanation up front, but I guess some diners are more interesting in the process than others and the chefs are just trying to keep everyone happy. \\n\\nUnfortunately, we had some real duds at our dinner - four guys who managed to be late for dinner and then showed about zero interest in the meal.  I couldn't believe how rude these guys were, especially given the cost of the meal.  But the chefs were gracious and didn't seem to mind all that much.\\n\\nAll in all we had a wonderful dinner and definitely recommend the experience.\n",
            "\n",
            "\n",
            "\n",
            "Text for false positive results:\n",
            "prediction:  3.0  actual:  0\n",
            "They are the biggest and one of the better looking among the modest restaurants in Terminal 4 B gates. The big pig on the wall with the retro typeface tries to subvert the overwhelming and inescapable airport food court vibe.\\n\\n\\nThe waitress was friendly and the service was prompt.\\n\\nI ordered a grilled cheese with tomato soup. The cheese was just tasteless and the soup was more salty than if it had come out of a can. I asked for coffee to go and it was barely lukewarm - made me think if the service was really as genuine as you can expect at an airport eatery.\\n\\nI will remember this place enough to not go there the next time I fly to Vegas through that airport.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  1\n",
            "Stayed at the hotel for 4 days. We ate breakfast here everyday and one dinner. The dinner left a lot to be desired. I ordered filet medium and it came out all red not medium. Waitress blamed it on st. Pats day specials. My daughter ordered a pasta and vegetable dish being vegan with oil on the side. It came all mixed together not on side.  \\n\\nShort order cook who does all eggs was fantastic! My wie ordered eggs benedict from kitchen rather tan wait in line for cooked to order.  They were just warm. This place needs to do a better job!\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  0\n",
            "Used to love this place.  The summer drink menu is disappointing and the service last time was lacking.  We went there for happy hour, and found out that we could only use our chip (Buy 1, Get 1 tap beers/wine) before 6 p.m.   It would have been nice if someone would have told us that, esp. since we went there only for happy hour.  This used to be the place to go for us (as a young mod place) with drinks that were $8-12 and well worth it.  After our last trip there, I am not sure we will be back.  Two drinks and an appetizer and our bill was nearly $40.  We are happy to pay that if the service is good and the menu has good selections.  This place is going to go under if they don't fix something.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "I'm always looking for a new spot to try and this place is about a mile from my house. We came in during happy hour and the place was pretty dead. Our server was nice and very attentive, but can tell he was bored with his lack of tables because he came over every 5 minutes. Food choices are American (burgers, salads, sandwiches). We ordered beers, which were $5 for craft beer pints. Beer choices here are good. For HH prices though, I wasn't too impressed. Appetizers are still between $5-10.\\n\\nFor dinner, I ordered the Wrangler burger and fries. I was told to stay far away from the coleslaw, as recommended by our server. My boyfriend ordered the philly cheesesteak and fries. Food arrived and mine tasted fine. My boyfriend said his philly was very dry and the bread was clearly burnt. He couldn't wait to leave. I can't say my burger was bad because it wasn't. I liked the egg bun too. Fries were not warm though and that was a bummer.\\n\\nWe didn't get dessert, just the check. We left for about $30. Sorry TapHouse but we won't be back. Nothing special here\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  0\n",
            "A 1 1/2 Stars from me! Dreadful! I spent the longest year of my life the fifteen minutes I spent looking for help in there! I wanted to know where the TV department was so I could look for HDTV's. No one knew where the TV department was! Finally, by use of my OWN EARS AND EYES I found it, saw high prices and left, thank God! Good service is \\\"How may I help you?\\\" heard from many salespeople. I heard none at all, had the feeling it was because I was a white man in a store with Latino and Black salespeople. Unacceptable! Dreadful store!\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "The service could be better.  Much better.  We waited about 10 minutes before we were asked for our drink, which was at the same time we ordered our food.  The food was good.  Not excellent, but definitely good.  I don't think I would go back again just for the mere reason that there are other places to try.  I wasn't extremely impressed.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "Decided to take the family out to a nice brunch, so we decided to go here. We heard good reviews so we decided to give it a try. The breakdown: Lakeview was great. The service was lagging. Constantly had to remind our server to refill waters. (Even when his section was empty). Appetizers took 30min for salmon tartare and French onion soup. By the time we got our main course we were full on bread and patience. First time here = bad experience. Food overall was ok. There's no definite wow factor.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  0\n",
            "Spazzing bartender started a shouting match with some friends of mine. If you like the smell of sewage over cigarette smoke, then this place is for you.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  1\n",
            "Such better options in Vegas! Let me just tell you that.  Decided to try Ago since we found a certificate on Restaurant.com right before our trip.  Very disappointed to get there and find out they won't accept them - make sure you get them off the site then.  The saving grace was we had the most FANTASTIC waiter.  He seriously gave us the best service and offered us some great deals instead.  Unfortunately the food was just meh. And the biggest disappointment? I asked for a side of Italian Sausage with my pasta and he said they don't have Italian sausage there. WHA?? What Italian restaurant doesn't have Italian sausage? Just another place in Vegas that is over priced, smaller portions that don't taste all that great. Find yourself somewhere else.  Oh and try to time it right -- we went right when Rehab was closed for the day and we found ourselves with a bunch of loud, drunk, hungry college kids. It's supposed to be a nicer restaurant and that just killed the mood.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  1\n",
            "I love trying out a new sushi place. I wished it was a bit better for me.\\n\\nArmed with an Amazon deal I purchased for $20 for $40 worth of food, we arrived for dinner on a Saturday night. Not very busy...\\n\\nOur server and sushi chef was friendly and helpful. As we looked at the menus handed to us and the monitor they had set up with pictures showing a slideshow of their sushi selections, we asked about their rolls. Our server knew some, yet still turned to ask most of what we asked to the sushi chef. I guess the new menu was new to them, too...?? \\n\\nWe ordered the Shufflin Roll recommended by our server and the James Special. Both were tasty, yet just had a lot going on. Couple different kinds of sauces, different fishes, sometimes a dish has too many things going on. I saw something called Taco Wasabi on their specials board, so I requested one. It was pretty much tako (octopus) chopped in a small bowl with wasabi mixed in. Do not recommend ordering that.\\n\\nWhen I presented my phone to use my Amazon deal, another employee came to settle our check so we can pay what's leftover after our voucher. I saw our check (what we would've paid) and saw that it added up to about $32. I'm not saying they were obligated to tell us, but all I was thinking was \\\"Wouldn't that have been nice that they could've told us we still had $8 to use???\\\" Or at least tell us what our balance was at. I'm not one to care if we go over a certain amount, especially using a voucher, because I knew we already got a deal. Anyone else understand where I'm coming from?? LOL\\n\\nI hate giving less than 3 stars, seeing that others did enjoy this place. Maybe I'll try again and write an update...\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "Fuel Pizza (uptown) Gets 1 star for being in uptown Charlotte' and another star for good customer service. Too bad the pizza is bland and flavorless, the side salad is colorful but lacks a good dressing to at least put it over the top. I thought the combos were too expensive for a pizza so flavorless and unexciting. \\n\\nYou can get a totally awesome tasting, HUGE, super slice of pizza for $6.50. Here you'll pay almost $8.00 for a drink, salad, and a decent size slice. I would say go to Sabarro's instead. You'll pay just a little more, but your meal will taste waaaay better. \\n\\nThe decor is interesting, but looks unfinished. The restrooms are clean, but they look nasty, with graffiti and poorly placed bathroom fixtures. I would think a \\\"theme restaurant\\\"  located in the heart of Uptown Charlotte would have a better looking design. Its a mess here. Glad I don't own this restaurant, I would be embarrassed to have it in my portfolio.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "Gestern ging es mit 6 Freunden zu Rim Wang hier mein Fazit zu diesem Thail\\u00e4nder:\\nEssen: Das Essen war ausgezeichnet. Ich hatte \\nGai Hoh Bei Toey (101 auf der Speisekarte) und war mit dem Essen restlos zufrieden. Auch den anderen hat es sehr gut bis ausgezeichnet geschmeckt.\\nPreise: Die Preise sind angemessen, wenn auch eher an der oberen Grenze, da die Portionen nicht allzu \\u00fcppig ausfielen.\\nAmbiente: Das Ambiente ist Geschmacksache. Gesamturteil OK, nur der Eingangsbereich zum WC ist nicht so toll.\\nService: Bis hierher h\\u00e4tte das Lokal 4-5 Punkte verdient. Verbockt hat es ganz klar der Service. Unfreundlich, unwirsch, fordernd und unflexibel. Ich finde das sehr schade, da einem der Besuch in einem ansonsten tollen Lokal mit guter K\\u00fcche verg\\u00e4llt wird. Das dr\\u00fcckt die Bewertung auf eine 2-3  eher Richtung 2.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  1\n",
            "We absolutely loved this place.\\n\\nThe food, the atmosphere, the service are all second to none.\\n\\nSo why the \\\"3-star\\\" rating?\\n\\nOver the top expensive!  $50 for a 12 year old?  Come on guys!   Ridiculous!\\n\\nBy the way, our favorite meat served was a chicken drummie that was encrusted with Parmesan cheese.  We had it last and if we would have had it first, we would have loaded up on it.\\n\\nAll the meats and salad bar are spectacular.  Really.\\n\\nOur servers were all exceptional.  It's really hard to find a better combination of food and service.\\n\\nI just take issue with anyone charging a 12 year old full price.\\n\\nLeave the kids at home and you'll enjoy a 4-star experience.\\n\\n\\nEDIT:  Just changed to 2 Star Rating.  Why?  Their website says 12 year olds get 1/2 price.  I told our main server my children were 12 and 10.  He replied, \\\"1/2 price for the 10 yo and full price for the 12 yo\\\".\\n\\nTrain your people!!!!!!  I'm now embarrassed for leaving a full 20% tip.  Damn.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "This place has sure changed...and not for the better. they totally re-did the menu and got rid of many yummy things they used to serve.\\nThere are still the desserts but the little sliders are off the menu and those were my favorite!\\nSo I bring my little guy here for a little dinner & chocolate treat. Our server tells me she is also a mom and whatnot. Ok lady..lets get this this started...I am with a 2 year old. I might be crazy but when the server says she is a parent I expect them to understand & TRY to be quick with things.\\nThis girl was not quick..she was very very slow.\\nFinally when the food arrived his grilled mac & cheese was cold. Thankfully he did not care. She offered to take it back and warm it up but there was no way he was going to go for that. He was hungry.\\nWe finally order the chocolate pizza for dessert after waiting way to long for her to come back and check on us.\\nThe pizza of course takes forever & I am trying to keep my kid from climbing the walls. Once it gets there tho my kiddo is in heaven. He tore into that pizza. He was in heaven. He was dancing in his chair...singing Yum Yum in my belly. It was awesome. And for that they should get 5 stars. But when I factor everything in they are down to 2 stars. Sorry Max..Prob wont be coming back again.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "This is perhaps the single most overrated place I've been to in Las Vegas.  I'm not sure why it's packed all the time except that it has a nice atmosphere and a great location.\\nWas not impressed with the sushi ,the pizza, nor the drinks.  They had some gals walking around giving out beer - that was cool eye candy but I can go to about 1,000 places locally for that.\\nDon't get it - prices aren't great either.  It is a nice happy hour place since the atmosphere is really cool.  But just not understanding the big appeal.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "I had both a red tinga as well as a chili verde gordita. I also enjoyed a large cup of the best Horchata in Las Vegas. Fresh and warm, the gorditas were filling and good.....but not great. Good for a quick stop, but there are much better options when looking for a full flavored, spicy, authentic gordita. The service was very friendly and the restaurant spotlessly clean, almost antiseptic.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  1\n",
            "You get what you pay for and the Riviera is no exception.  The Casino is definitely dated but doesn't feel as dingy as it could.  The rooms are comfortable and the pool is decent.  Worth leaving the property to find good food.  The walk to the strip is fairly quick too.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  0\n",
            "I am not a big fan of AMANDA (owner and waitress), or Fuego Del Mar A.K.A. Fuego Tacos! \\nIf you are new in the area or just visiting, please watch out for this restaurant!! I assure you this place will give you suspicions.\\nWhat's the point of having a groupon deal if the business does not welcome newcomers! Please please be careful yelpers.\\n\\n(Just needed to repost here)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# overall we can tell the modal did a pretty good job on \n",
        "conf_matrix = confusion_matrix(predictions_2_df['prediction_label'], predictions_2_df['actual_score'])\n",
        "print(conf_matrix)\n",
        "\n",
        "# Define TF and FT rows based on prediction score and actual score\n",
        "false_negative_rows = predictions_2_df[(predictions_2_df['prediction_label'] != predictions_2_df['actual_score']) & \n",
        "                          ((predictions_2_df['prediction_label'] == 0) | (predictions_2_df['prediction_label'] == 1)) & \n",
        "                          ((predictions_2_df['actual_score'] == 3) | (predictions_2_df['actual_score'] == 4))]\n",
        "\n",
        "false_positive_rows = predictions_2_df[(predictions_2_df['prediction_label'] != predictions_2_df['actual_score']) & \n",
        "                           ((predictions_2_df['prediction_label'] == 3) | (predictions_2_df['prediction_label'] == 4)) & \n",
        "                          ((predictions_2_df['actual_score'] == 0) | (predictions_2_df['actual_score'] == 1))]\n",
        "\n",
        "\n",
        "print(\"Text for false negative results:\")\n",
        "for idx, row in false_negative_rows.iterrows():\n",
        "    print('prediction: ', row['prediction_label'], ' actual: ', row['actual_score'])\n",
        "    print(row['text'])\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\"\\nText for false positive results:\")\n",
        "for idx, row in false_positive_rows.iterrows():\n",
        "    print('prediction: ', row['prediction_label'], ' actual: ', row['actual_score'])\n",
        "    print(row['text'])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# analysis:\n",
        "#\n",
        "# false negative breakdown:\n",
        "#   - words like 'only' 'once' 'won't' 'closed!!!' 'why' '?' '!' 'too bad' are used, modal get confused easily on excalaimation sentences\n",
        "#   - seeing more false negative compared to last modal\n",
        "#\n",
        "# false positive breakdown:\n",
        "#   - reviews are mixed with good and bad comments. 'used to love' 'loved', also 'comfortable' etc were mixed in bad words. Modal seems to give more weight on positive words\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4c72iOlhraz",
        "outputId": "230263e0-ee21-4a24-b1ba-b2774489a89b"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Define a function to apply sentiment analysis over a batch of reviews\n",
        "tokenizer_3 = AutoTokenizer.from_pretrained(\"nihaldsouza1/yelp-rating-classification\")\n",
        "model_3 = AutoModelForSequenceClassification.from_pretrained(\"nihaldsouza1/yelp-rating-classification\")\n",
        "pipeline_3 = pipeline(task='sentiment-analysis', model=model_3,tokenizer=tokenizer_3)\n",
        "\n",
        "def perform_sentiment_analysis_3(text):\n",
        "    sentiment_prediction = pipeline_3(preprocess_text(text))[0]\n",
        "    sentiment_prediction_label = int(sentiment_prediction['label'][0])-1\n",
        "    sentiment_prediction_score=sentiment_prediction['score']\n",
        "    return [sentiment_prediction_label, sentiment_prediction_score]\n",
        "\n",
        "\n",
        "predictions_3_df = pd.DataFrame({'actual_score': sampled_test_df['label'], 'text': sampled_test_df['text']})\n",
        "\n",
        "predictions_3_df[['prediction_label','prediction_score']] = sampled_test_df['text'].apply(perform_sentiment_analysis_3).apply(pd.Series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.58\n",
            "Index(['actual_score', 'text', 'prediction_label', 'prediction_score'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "accuracy_3 = accuracy_score(predictions_3_df['actual_score'], predictions_3_df['prediction_label'])\n",
        "print(accuracy_3)\n",
        "\n",
        "print(predictions_3_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[86 41  8  3  4]\n",
            " [22 42 10  2  1]\n",
            " [ 1 23 55 11  4]\n",
            " [ 1  5 18 46 16]\n",
            " [ 0  1  1 38 61]]\n",
            "Text for false negative results:\n",
            "prediction:  1.0  actual:  3\n",
            "I have only been to MADCAP once, to see \\\"Until the Light Takes Us\\\" - a documentary about KVLT Norwegian Black Metal. I am very excited to have a theater playing REAL independent films and cult classics nearby. I frequently visited Chandler Cinemas to see films put on by Midnight Movie Mamacita - Cannibal Holocaust, El Topo, The Holy Mountain, Re-animator, Black Christmas.. etc. I was very disappointed to see that theater go. When I found out that she'd been relocated to continue the tradition at MADCAP, I rejoiced. I look forward to seeing many movies here in the future.\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  3\n",
            "I don't have a whole lot of experience with liquor stores, but have always been pleased here.  The staff are always nice, helpful, and non-intrusive.\\n\\nI once went with my boyfriend, who expressed a desire for a certain beer that they didn't have.  The dude behind the counter immediately said that they would order it.  Lo and behold, the next time we went, there it was.  We proceeded to buy lots of it.  Everything after that is kind of a blur.\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  4\n",
            "Got a week?  That's about how long it would take to visit all the stores in this Mall.  I went on a Friday night and the place was packed with happy shoppers.  They have every store that you could ever dream of, plus some that you never thought of.  I was weighted down with packages in no time and my feet were so tired by the time made it from Nordstroms to Dillards, I gave up and went back to my hotel!\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  4\n",
            "I don't really do the lounge scene back home due to one really bad experience a few years ago at Enclave. I wouldn't go as far as to call Enclave much of a lounge, but they all kind of seem the same to me. Until I met Bond. It was a \\\"one-thing-led to-another\\\" relationship with Bond. *Blush!*\\n\\nI visited Bond about 3 times over the course of one week and even decided to stay at his place on my last night! Well, by his place, I really mean the Cosmopolitan. And it was with my husband for our final night in Vegas, so I guess it was kind of a threesome. Yeeah... about Bond.\\n\\nThe music is pumping, but not obnoxious. The DJ was great. The decor is excellent. The seats are comfy. The scene is full of variety, but not like a douche circus. I drinks? Don Johnson joined me a few times. The staff? Friendly and fabulous. I donned my glitzy best and can't wait to visit again on my next trip through town.\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "Prior to NYC having any Whole Foods location I was OBSESSED with any location I happened upon. We have had WF for over a decade now in NYC but I still visit other locations with interest. This is one of the nicest I have been to probably in part because it is quite new. (having opened last September one of the employees told me) The outdoor seating area on the 2nd floor is nice. \\n\\nClearly we are not in NYC as one of the deals in the prepared foods area was 4 for $4 where you could get 4 of the salads (healthy selections designations) for $4. The soup selection was pretty good the only thing I would say is the hot/cold prepared foods on the buffet were kind of so so.\\n\\nLots of available parking downstairs.\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "On our recent trip to Vegas I researched different restaurants to try - turns out that Dos Caminos AND Isla have closed. We knew we'd be in the Cosmo for the Secret Pizza (that's another review) and I wanted to try China Poblano after reading the menu on the Cosmo website. What I DIDN'T do is check the Yelp! reviews, and I'm glad I didn't. What we experienced was so far different from most reviews that I've just read!\\nOK look - when you're on vacation, you tend to spend money. $15 drinks are the going price at upscale hotels. And the \\\"salt air margarita\\\" (I just HAD to try one) was worth every cent!  I have no idea how they do it - the salt cloud that floats on the surface of the drink stays there as you drink, so with every sip you get a piece of salt heaven. \\nThe wait staff were friendly and efficient. The manager, I\\u00f1igo, even stopped by to chat with K'ayum (age 8) and watched him do his latest magic trick.  We ordered queso fundido with chorizo. It came with fresh-made tortillas and was excellent. Adriana got a carnitas taco and she was thrilled with the chicharr\\u00f3n topping. I had a fish taco which was fantastic, and K'ayum had some noodles which he devoured (and he's a picky eater!). \\nThe drinks were what really got me excited. After the \\\"salt air margarita\\\" I had another specialty called a \\\"Mexican gin and tonic.\\\" It's made with cilantro, elderflower liqueur, and I don't know what else, but it worked. For dessert I had a tequila flight that came with house-made sangrita that was sublime!  I wish I had a bottle of their sangrita for sipping tequila here at home!\\nAnyway, it's a week later and we're still talking about our experience. We loved the decor, the ambiance, the service, the food, and the drinks. We'll be back!\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  4\n",
            "If you find yourself in need of eyeglasses...this is the place to go.  My prescription requires a very high correction. Visited all the local vendors, Sears, Pearl Vision, Eye Glass world, Sams, Walmart. Someone mentioned Costco to me....they blew all the other vendors out of the water. They have a great selection of frames, many options are included in the price. Didn't try to up-sell to something I couldn't afford.....When you need new fames/lens this is your one stop shop\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  4\n",
            "My husband made reservations at this restaurant for my birthday dinner. We had reservations at 6:30 and had the restaurant to ourselves for a good 45 minutes before any other guests arrived. We had a window table with a fantastic view of the strip from the Stratosphere all the way down to Mandalay Bay, as this restaurant is on the 56th floor of the ivory tower in the Palms Hotel/Casino.\\n\\nWe arrived and our waiter Salvano greeted us and took our drink orders. We ordered off of the tasting course menu. This menu consist of 7 courses. You have a choice of 3 options for each course including one vegetarian option. So the variations are numerous. My husband and I decided to get different entrees for each course to maximize our experience to taste as much of the menu as possible.\\n\\nThe first course was a complimentary sampling from the chef. It was pheasant with filo dough wrap, with a strawberry puree, and a cauliflower puree soup. It was a nice surprise to start the evening from the chef.\\n\\n1st course: Russian Golden Ostera caviar and Truffle caviar.($20 supplement)\\n\\n2nd course: Ribeye Carpaccio and Maine Lobster and herb salad\\n\\n3rd course: Sauteed foie gras and Chilled terrine of foie gras\\n\\n4th course: King crab leg croustillant and Tempura calamari\\n\\n5th course: Sauteed Dove Sole and Red Snapper\\n\\n6th course: Aged beef ribeye and Spring rabbit\\n\\nChef palate cleanser consist of meringue coating around grapefruit puree and poppyseed sauce.\\n\\n7th course. Gran Marinier souffle and Chocolate souffle.\\n\\nOverall the dishes were decent size. The variety and flavors in each course made it so unique and delicious. With the foie gras the waiter recommended a glass of Sauternes wine, which was a pairing. The service was impeccable, even when it got busy the wait staff worked as a team to keep up the incredible service. Every waiter was knowledgeable and described in detail each dish as they served it. The view is priceless especially as dusk turned to night and you could see a clear view of the strip lighting up. Awesome!!. Walked out feeling as if we had spent the day at the spa. Totally relaxed and satisfied. Definitely recommend Alize for a very special occasion.\n",
            "\n",
            "\n",
            "prediction:  0.0  actual:  3\n",
            "Was in conference at the Phoenix Convention Center and a glorious smell wafted through from the east. Turning to my left I saw a plate, and lady tearing something up..fiercely . Me and three other people immediately stopped what we were doing and walked somewhat zombie like to where the food was and asked...where did you get that? Karim's Cobbler Shop and Deli was her reply...in between bites.  \\n\\nNow I've been in Phoenix for 3 months looking for a taste of soul food. And here it was in my back yard! I was shocked!!!\\n\\nWith a sense of urgency I walked the streets until once again I was seduced by the smell of fried fish. Wasnt very far, and it was perched right in front of the Light Rail.  My kind of place.\\n\\nFirst thought, very humble. Very clean and neat and humble.  The owner was very kind, friendly and humble. Very confident that whatever I ordered I would love it. And I did.\\n\\nAs the only customer in the place I had soo many questions..How long were you here. Where do you market you store, cuz I never heard of it. With a smile he explained that his customers usually come in thru word of mouth and via the smell.\\n\\nI ordered the 3 piece whiting (its a east coast thing) It was well seasoned yet  non-greasy and well I wanted more of it. A side of red rice and beans which was flavorful and simply not enough.  Not usually a peach cobbler fan but it had so many intricate flavors. I sensed some clove, cinnamon, brown sugar...and something I can't quite put my finger on. The detective will be back to figure out this mystery.  It was sooo GOOOD!\\n\\n\\nHearing so many complaints that Phoenix has alot of sun but no soul I can confidently say that there is however scatter amongst the desert.  One just have to put in the detective work. Use the senses...it will lead you there. But if you can't follow my lead.  Karim's Cobbler shop is the place to get your grub on.  Bring your families and friends too.  Everyone will leave happy. Or with an extra side :)\n",
            "\n",
            "\n",
            "prediction:  1.0  actual:  4\n",
            "Bam!  That's how excited I am to write this review.  I've had Cafe Du Jour bookmarked \\\"To Try\\\" for over a year, and I'm angry I haven't come sooner.  We had one of our best dinners in the 'burgh the past two years.  \\n\\nIt was sold to me as a French Bistro - but it's really not.  None of the items are classic French comfort food, such as a coq au vin, duck confit, pate, or other type of items.  I think it falls in the New American cuisine.  Correction, it is delicious New American cuisine.  Soy-glazed meatballs ($10), pork, apple butter and brie crostini ($10), fennel rubbed pork chop with crispy kale($24), chicken breast stuffed with feta and spinach ($24), are some of the items that I can recall.\\n\\nThere isn't a website, and the menu you can find on allmenus seems to be a lunch menu, and outdated.  I wouldn't let that deter you at all - you just have to trust your fellow Yelpers who rave about this place.  I do disagree on the $$ designation.  Two people with 2 apps, 2 entrees, 1 desert, and a cork fee was $86 (and $100 adding tip).\\n\\nNow, it is small, or at least while the patio is closed.  8 tables or so, and only 4 staff it seemed.  One host/waiter/runner, one chef, one sous chef, and an extra hand.  The pace between our courses was a bit longer than usual, but it didn't really bother me like it usually does.  The staff is working hard, and you can see it, and the food is so good I didn't really care.  And as mentioned elsewhere, BYOB with $2/stem.\\n\\nThis restaurant needs to be the next place you go.\n",
            "\n",
            "\n",
            "\n",
            "Text for false positive results:\n",
            "prediction:  3.0  actual:  0\n",
            "I had a pretty good time at this place soon after it opened.  The music was really good.\\n\\nCut to a year later- I spent 6 months planning my sister's bachelorette party in Vegas.  We went all out.  I decided on Tryst for our last night in Vegas and called a month ahead to reserve a table.  The manager said \\\"no problem\\\" and took my name.  This was the first time I reserved a table at a bar and didn't have to put down a credit card- weird.  Well, I found out why we didn't need a credit card, when 8 of us arrived we passed up the line and were told at the door that they didn't have our reservation.  I called the idiot I booked with and he finally returned my call an hour later mumbling about being sorry.  No \\\"sorry\\\" would ever make up for that, I had 8 girls wondering what the hell was going on, plus the night was ruined for my sister- which I can't stand to think about.  I can't redo a bachelorette party\\n\\nThere are a lot of nightclubs to choose from in Vegas!  I trusted this place to take care of us, we got f**ked. \\n\\nNow I am planning my cousins big birthday weekend.  Do you think I will suggest Tryst?\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "We just moved to MTL and he had never had a smoked meat! We were a bit lost and hungry and stumbled upon this Dunns location. The roomies had just has a great Dunns experience back home. So I decided this would be a great place to intro TJ to the smoked meat sandwich. I was wrong. We split the traditional medium smoked meat platter (sandwich, fries, coleslaw, and a pickle). Positives - enough food for two, the fries were good and plentiful, pickle was tasty. Negatives - a bit on the pricey side (~$15 for what is supposed to feed one person),  smoked meat was meh (dry, salty, overly processed). Overall it was ok but I'll have a hard time convince him to try smoked meat again.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "Gestern ging es mit 6 Freunden zu Rim Wang hier mein Fazit zu diesem Thail\\u00e4nder:\\nEssen: Das Essen war ausgezeichnet. Ich hatte \\nGai Hoh Bei Toey (101 auf der Speisekarte) und war mit dem Essen restlos zufrieden. Auch den anderen hat es sehr gut bis ausgezeichnet geschmeckt.\\nPreise: Die Preise sind angemessen, wenn auch eher an der oberen Grenze, da die Portionen nicht allzu \\u00fcppig ausfielen.\\nAmbiente: Das Ambiente ist Geschmacksache. Gesamturteil OK, nur der Eingangsbereich zum WC ist nicht so toll.\\nService: Bis hierher h\\u00e4tte das Lokal 4-5 Punkte verdient. Verbockt hat es ganz klar der Service. Unfreundlich, unwirsch, fordernd und unflexibel. Ich finde das sehr schade, da einem der Besuch in einem ansonsten tollen Lokal mit guter K\\u00fcche verg\\u00e4llt wird. Das dr\\u00fcckt die Bewertung auf eine 2-3  eher Richtung 2.\n",
            "\n",
            "\n",
            "prediction:  4.0  actual:  1\n",
            "We absolutely loved this place.\\n\\nThe food, the atmosphere, the service are all second to none.\\n\\nSo why the \\\"3-star\\\" rating?\\n\\nOver the top expensive!  $50 for a 12 year old?  Come on guys!   Ridiculous!\\n\\nBy the way, our favorite meat served was a chicken drummie that was encrusted with Parmesan cheese.  We had it last and if we would have had it first, we would have loaded up on it.\\n\\nAll the meats and salad bar are spectacular.  Really.\\n\\nOur servers were all exceptional.  It's really hard to find a better combination of food and service.\\n\\nI just take issue with anyone charging a 12 year old full price.\\n\\nLeave the kids at home and you'll enjoy a 4-star experience.\\n\\n\\nEDIT:  Just changed to 2 Star Rating.  Why?  Their website says 12 year olds get 1/2 price.  I told our main server my children were 12 and 10.  He replied, \\\"1/2 price for the 10 yo and full price for the 12 yo\\\".\\n\\nTrain your people!!!!!!  I'm now embarrassed for leaving a full 20% tip.  Damn.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "This place has sure changed...and not for the better. they totally re-did the menu and got rid of many yummy things they used to serve.\\nThere are still the desserts but the little sliders are off the menu and those were my favorite!\\nSo I bring my little guy here for a little dinner & chocolate treat. Our server tells me she is also a mom and whatnot. Ok lady..lets get this this started...I am with a 2 year old. I might be crazy but when the server says she is a parent I expect them to understand & TRY to be quick with things.\\nThis girl was not quick..she was very very slow.\\nFinally when the food arrived his grilled mac & cheese was cold. Thankfully he did not care. She offered to take it back and warm it up but there was no way he was going to go for that. He was hungry.\\nWe finally order the chocolate pizza for dessert after waiting way to long for her to come back and check on us.\\nThe pizza of course takes forever & I am trying to keep my kid from climbing the walls. Once it gets there tho my kiddo is in heaven. He tore into that pizza. He was in heaven. He was dancing in his chair...singing Yum Yum in my belly. It was awesome. And for that they should get 5 stars. But when I factor everything in they are down to 2 stars. Sorry Max..Prob wont be coming back again.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "Courtney's review is pretty much spot on. I can't think of a better way to describe the show other than Rick Thomas revels in himself. Between his magic tricks, he talks about how he followed his dreams and shows weird, outdated video segments about his life. Like the video of him doing the cha cha with his sister when he was 14 while the words \\\"You go boy!\\\" fly across the screen. ?? I came for magic and tigers, Rick. Not to see your weird home vids. Rick also repeats some crazy nonsense about dreams throughout the show. And I don't mean cutesy, Disney, 'follow your dreams' stuff. More like weird philosophical theories that make you say, \\\"wtf is he talking about?\\\" Also, the show tended to bob between the magic of childhood and him dry humping his sexy assistants on stage. All in all, it was pretty ridiculous and made my jaw drop several times. But I still had a great time with friends because we laughed about it long after the show ended.\n",
            "\n",
            "\n",
            "prediction:  3.0  actual:  1\n",
            "You get what you pay for and the Riviera is no exception.  The Casino is definitely dated but doesn't feel as dingy as it could.  The rooms are comfortable and the pool is decent.  Worth leaving the property to find good food.  The walk to the strip is fairly quick too.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# overall we can tell the modal did a pretty good job on \n",
        "conf_matrix = confusion_matrix(predictions_3_df['prediction_label'], predictions_3_df['actual_score'])\n",
        "print(conf_matrix)\n",
        "\n",
        "# Define TF and FT rows based on prediction score and actual score\n",
        "false_negative_rows = predictions_3_df[(predictions_3_df['prediction_label'] != predictions_3_df['actual_score']) & \n",
        "                          ((predictions_3_df['prediction_label'] == 0) | (predictions_3_df['prediction_label'] == 1)) & \n",
        "                          ((predictions_3_df['actual_score'] == 3) | (predictions_3_df['actual_score'] == 4))]\n",
        "\n",
        "false_positive_rows = predictions_3_df[(predictions_3_df['prediction_label'] != predictions_3_df['actual_score']) & \n",
        "                           ((predictions_3_df['prediction_label'] == 3) | (predictions_3_df['prediction_label'] == 4)) & \n",
        "                          ((predictions_3_df['actual_score'] == 0) | (predictions_3_df['actual_score'] == 1))]\n",
        "\n",
        "\n",
        "print(\"Text for false negative results:\")\n",
        "for idx, row in false_negative_rows.iterrows():\n",
        "    print('prediction: ', row['prediction_label'], ' actual: ', row['actual_score'])\n",
        "    print(row['text'])\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\"\\nText for false positive results:\")\n",
        "for idx, row in false_positive_rows.iterrows():\n",
        "    print('prediction: ', row['prediction_label'], ' actual: ', row['actual_score'])\n",
        "    print(row['text'])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# analysis:\n",
        "#\n",
        "# false negative breakdown:\n",
        "#   - sentences are confusing. 'angry I haven't come sooner.' modal did not do a good job analyzing semantic meanings.\n",
        "#   - negative words are used: won't, can't\n",
        "#\n",
        "# false positive breakdown:\n",
        "#   - past tense positive reviews confused the modal: 'had a pretty good time', 'was really good', 'had a great..' followed with 'I was wrong'\n",
        "#   - foreign language not regonized by modal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz3KPFl4HTyE",
        "outputId": "8545fa28-c9b6-450f-b7fd-3521fa796f19"
      },
      "outputs": [],
      "source": [
        "# Text Summarization\n",
        "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
        "\n",
        "def perform_summarizing(text):\n",
        "    processedText = preprocess_text(text)\n",
        "    summary = summarizer(processedText, min_length=20, max_length=512)[0]['summary_text']\n",
        "    print(summary)\n",
        "    return summary\n",
        "\n",
        "sampled = sampled_test_df.sample(n=300, random_state=42)\n",
        "summary_df = pd.DataFrame({'actual_score': sampled['label'], 'text': sampled['text']})\n",
        "\n",
        "\n",
        "summary_df['summary'] = summary_df['text'].apply(perform_summarizing)\n",
        "print(summary_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX3FUi2I3A4d"
      },
      "source": [
        "### After summarization, we applied the previous used three kinds of sentiment analysis on summarized data, and we are observing a decrease of accuracy in all three methods. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ANr4oMUVwlWx",
        "outputId": "5f9efc8d-7656-4087-8cae-e2f2d8c678e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before summary_1:  0.666\n",
            "accuracy_summary_1:  0.5033333333333333\n",
            "before summary_2:  0.434\n",
            "accuracy_summary_2:  0.3566666666666667\n",
            "before summary_3:  0.58\n",
            "accuracy_summary_3:  0.4766666666666667\n"
          ]
        }
      ],
      "source": [
        "summary_df[['prediction_1_label','prediction_1_score']] = summary_df['summary'].apply(perform_sentiment_analysis_1).apply(pd.Series)\n",
        "summary_df[['prediction_2_label','prediction_2_score']] = summary_df['summary'].apply(perform_sentiment_analysis_2).apply(pd.Series)\n",
        "summary_df[['prediction_3_label','prediction_3_score']] = summary_df['summary'].apply(perform_sentiment_analysis_3).apply(pd.Series)\n",
        "\n",
        "accuracy_summary_1 = accuracy_score(summary_df['actual_score'], summary_df['prediction_1_label'])\n",
        "accuracy_summary_2 = accuracy_score(summary_df['actual_score'], summary_df['prediction_2_label'])\n",
        "accuracy_summary_3 = accuracy_score(summary_df['actual_score'], summary_df['prediction_3_label'])\n",
        "\n",
        "# sampled_test_df_backup[['prediction_1_label','prediction_1_score']] = sampled_test_df_backup['summary'].apply(perform_sentiment_analysis_1).apply(pd.Series)\n",
        "# sampled_test_df_backup[['prediction_2_label','prediction_2_score']] = sampled_test_df_backup['summary'].apply(perform_sentiment_analysis_2).apply(pd.Series)\n",
        "# sampled_test_df_backup[['prediction_3_label','prediction_3_score']] = sampled_test_df_backup['summary'].apply(perform_sentiment_analysis_3).apply(pd.Series)\n",
        "\n",
        "# accuracy_summary_1 = accuracy_score(sampled_test_df_backup['actual_score'], sampled_test_df_backup['prediction_1_label'])\n",
        "# accuracy_summary_2 = accuracy_score(sampled_test_df_backup['actual_score'], sampled_test_df_backup['prediction_2_label'])\n",
        "# accuracy_summary_3 = accuracy_score(sampled_test_df_backup['actual_score'], sampled_test_df_backup['prediction_3_label'])\n",
        "\n",
        "\n",
        "print('before summary_1: ', accuracy_1)\n",
        "print('accuracy_summary_1: ', accuracy_summary_1)\n",
        "print('before summary_2: ', accuracy_2)\n",
        "print('accuracy_summary_2: ', accuracy_summary_2)\n",
        "print('before summary_3: ', accuracy_3)\n",
        "print('accuracy_summary_3: ', accuracy_summary_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### randomly select 100 rows and manually mark the categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaASRAdMx8BD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# sampled = sampled_test_df.sample(n=100, random_state=42)\n",
        "\n",
        "# # Export selected rows to CSV\n",
        "# sampled.to_csv('./random_100.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  label                                               text  \\\n",
            "0         361      0  If you've ever eaten good Mexican food in your...   \n",
            "1          73      3  Everything you need is here.\\n\\nWe stayed here...   \n",
            "2         374      3  We went for an early Saturday night dinner, dr...   \n",
            "3         155      3  This is a new fav happy hour place for us, we'...   \n",
            "4         104      1  I dunno, I was drunk when I got there.  It's a...   \n",
            "\n",
            "      category  \n",
            "0  restaurants  \n",
            "1       hotels  \n",
            "2  restaurants  \n",
            "3  restaurants  \n",
            "4          bar  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Read DataFrame from CSV file\n",
        "manually_marked_df = pd.read_csv('./manually_marked_df.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(manually_marked_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Three zero-shot classification modal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "candidate_labels = [\n",
        "    \"restaurants\",\n",
        "    \"bars\",\n",
        "    \"coffee shops\",\n",
        "    \"hotels\",\n",
        "    \"salons/barbershops\",\n",
        "    \"auto repair\",\n",
        "    \"home services\",\n",
        "    \"medical services\",\n",
        "    \"entertainment\",\n",
        "    \"pet services\",\n",
        "    \"financial services\",\n",
        "    \"travel & tourism\",\n",
        "    \"education\",\n",
        "    \"real estate\",\n",
        "    \"fitness\",\n",
        "    \"landscaping & gardening services\",\n",
        "    \"legal services\",\n",
        "    \"photography services\",\n",
        "    \"childcare services\",\n",
        "    \"computer & technology services\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X25sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     max_score \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m][max_index]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X25sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [max_label, max_score]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m manually_marked_df[[\u001b[39m'\u001b[39m\u001b[39mpredication_category\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpredication_category_score\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m manually_marked_df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(perform_facebook_classifier)\u001b[39m.\u001b[39mapply(pd\u001b[39m.\u001b[39mSeries)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4898\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4899\u001b[0m         func,\n\u001b[1;32m   4900\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4901\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4902\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4903\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4904\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
            "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb Cell 20\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperform_facebook_classifier\u001b[39m(text):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     output \u001b[39m=\u001b[39m facebook_classifier(preprocess_text(text), candidate_labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# Find the index of the label with the highest score\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     max_index \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mindex(\u001b[39mmax\u001b[39m(output[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m]))\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to understand extra arguments \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(sequences, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/base.py:1188\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1187\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1189\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1190\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   1191\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1192\u001b[0m             )\n\u001b[1;32m   1193\u001b[0m         )\n\u001b[1;32m   1194\u001b[0m     )\n\u001b[1;32m   1195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/base.py:1102\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1101\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1102\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1103\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(model_forward)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcandidate_label\u001b[39m\u001b[39m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m model_outputs\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1891\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1886\u001b[0m \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1888\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing input embeddings is currently not supported for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1889\u001b[0m     )\n\u001b[0;32m-> 1891\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1892\u001b[0m     input_ids,\n\u001b[1;32m   1893\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1894\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1895\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1896\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1897\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1898\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1899\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1900\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1901\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1902\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1903\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1904\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1905\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1906\u001b[0m )\n\u001b[1;32m   1907\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]  \u001b[39m# last hidden state\u001b[39;00m\n\u001b[1;32m   1909\u001b[0m eos_mask \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39meq(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39meos_token_id)\u001b[39m.\u001b[39mto(hidden_states\u001b[39m.\u001b[39mdevice)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1617\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1611\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1612\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1613\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1614\u001b[0m     )\n\u001b[1;32m   1616\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1617\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1618\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1619\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1620\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1621\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1622\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1623\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1624\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1625\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1626\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1627\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1628\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1629\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1633\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:1470\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1458\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m   1459\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         use_cache,\n\u001b[1;32m   1468\u001b[0m     )\n\u001b[1;32m   1469\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1470\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m   1471\u001b[0m         hidden_states,\n\u001b[1;32m   1472\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1473\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1474\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1475\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1476\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49m(\n\u001b[1;32m   1477\u001b[0m             cross_attn_head_mask[idx] \u001b[39mif\u001b[39;49;00m cross_attn_head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m   1478\u001b[0m         ),\n\u001b[1;32m   1479\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1480\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1481\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1482\u001b[0m     )\n\u001b[1;32m   1483\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:779\u001b[0m, in \u001b[0;36mBartDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[1;32m    778\u001b[0m cross_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m hidden_states, cross_attn_weights, cross_attn_present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_attn(\n\u001b[1;32m    780\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    781\u001b[0m     key_value_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    782\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    783\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m    784\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mcross_attn_past_key_value,\n\u001b[1;32m    785\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    786\u001b[0m )\n\u001b[1;32m    787\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m    788\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:563\u001b[0m, in \u001b[0;36mBartSdpaAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    560\u001b[0m     value_states \u001b[39m=\u001b[39m past_key_value[\u001b[39m1\u001b[39m]\n\u001b[1;32m    561\u001b[0m \u001b[39melif\u001b[39;00m is_cross_attention:\n\u001b[1;32m    562\u001b[0m     \u001b[39m# cross_attentions\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m     key_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_proj(key_value_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[1;32m    564\u001b[0m     value_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj(key_value_states), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, bsz)\n\u001b[1;32m    565\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# reuse k, v, self_attention\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# bart\n",
        "from transformers import pipeline\n",
        "facebook_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "def perform_facebook_classifier(text):\n",
        "    output = facebook_classifier(preprocess_text(text), candidate_labels)\n",
        "    # Find the index of the label with the highest score\n",
        "    max_index = output['scores'].index(max(output['scores']))\n",
        "\n",
        "    # Get the label with the highest score\n",
        "    max_label = output['labels'][max_index]\n",
        "\n",
        "    # Get the score of the label with the highest score\n",
        "    max_score = output['scores'][max_index]\n",
        "    return [max_label, max_score]\n",
        "\n",
        "manually_marked_df[['predication_category', 'predication_category_score']] = manually_marked_df['text'].apply(perform_facebook_classifier).apply(pd.Series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.58\n"
          ]
        }
      ],
      "source": [
        "accuracy_class_predict = accuracy_score(manually_marked_df['category'], manually_marked_df['predication_category'])\n",
        "print(accuracy_class_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.11/site-packages (0.2.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     max_score \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m][max_index]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [max_label, max_score]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m manually_marked_df[[\u001b[39m'\u001b[39m\u001b[39mdeberta_predication_category\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdeberta_predication_category_score\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m manually_marked_df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(perform_deberta_classifier)\u001b[39m.\u001b[39mapply(pd\u001b[39m.\u001b[39mSeries)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m accuracy_class_predict \u001b[39m=\u001b[39m accuracy_score(manually_marked_df[\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m], manually_marked_df[\u001b[39m'\u001b[39m\u001b[39mdeberta_predication_category\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(accuracy_class_predict)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4898\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4899\u001b[0m         func,\n\u001b[1;32m   4900\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4901\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4902\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4903\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4904\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
            "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb Cell 22\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperform_deberta_classifier\u001b[39m(text):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     output \u001b[39m=\u001b[39m deberta_classifier(preprocess_text(text), candidate_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Find the index of the label with the highest score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangyang/Documents/CS6120/hw4/hw4.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     max_index \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mindex(\u001b[39mmax\u001b[39m(output[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m]))\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to understand extra arguments \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(sequences, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/base.py:1188\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1187\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1189\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1190\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   1191\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1192\u001b[0m             )\n\u001b[1;32m   1193\u001b[0m         )\n\u001b[1;32m   1194\u001b[0m     )\n\u001b[1;32m   1195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[39mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed, torch\u001b[39m.\u001b[39mTensor):\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/base.py:1102\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1101\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1102\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1103\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(model_forward)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcandidate_label\u001b[39m\u001b[39m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msequence\u001b[39m\u001b[39m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m: inputs[\u001b[39m\"\u001b[39m\u001b[39mis_last\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m model_outputs\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1300\u001b[0m, in \u001b[0;36mDebertaV2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1300\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeberta(\n\u001b[1;32m   1301\u001b[0m     input_ids,\n\u001b[1;32m   1302\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1303\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1304\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1305\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1306\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1307\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1308\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1309\u001b[0m )\n\u001b[1;32m   1311\u001b[0m encoder_layer \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1312\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(encoder_layer)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:1070\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m   1062\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1063\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1064\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m   1068\u001b[0m )\n\u001b[0;32m-> 1070\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1071\u001b[0m     embedding_output,\n\u001b[1;32m   1072\u001b[0m     attention_mask,\n\u001b[1;32m   1073\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1074\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1075\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1076\u001b[0m )\n\u001b[1;32m   1077\u001b[0m encoded_layers \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1079\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:514\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    504\u001b[0m     output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    505\u001b[0m         layer_module\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    506\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         output_attentions,\n\u001b[1;32m    512\u001b[0m     )\n\u001b[1;32m    513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 514\u001b[0m     output_states \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    515\u001b[0m         next_kv,\n\u001b[1;32m    516\u001b[0m         attention_mask,\n\u001b[1;32m    517\u001b[0m         query_states\u001b[39m=\u001b[39;49mquery_states,\n\u001b[1;32m    518\u001b[0m         relative_pos\u001b[39m=\u001b[39;49mrelative_pos,\n\u001b[1;32m    519\u001b[0m         rel_embeddings\u001b[39m=\u001b[39;49mrel_embeddings,\n\u001b[1;32m    520\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    524\u001b[0m     output_states, att_m \u001b[39m=\u001b[39m output_states\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:373\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    371\u001b[0m     attention_output, att_matrix \u001b[39m=\u001b[39m attention_output\n\u001b[1;32m    372\u001b[0m intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 373\u001b[0m layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    374\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    375\u001b[0m     \u001b[39mreturn\u001b[39;00m (layer_output, att_matrix)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:339\u001b[0m, in \u001b[0;36mDebertaV2Output.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, input_tensor):\n\u001b[0;32m--> 339\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    340\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    341\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip3 install sentencepiece\n",
        "# deberta classifier\n",
        "from transformers import pipeline\n",
        "\n",
        "deberta_classifier = pipeline(\"zero-shot-classification\",model=\"sileod/deberta-v3-base-tasksource-nli\")\n",
        "\n",
        "\n",
        "def perform_deberta_classifier(text):\n",
        "    output = deberta_classifier(preprocess_text(text), candidate_labels)\n",
        "    # Find the index of the label with the highest score\n",
        "    max_index = output['scores'].index(max(output['scores']))\n",
        "\n",
        "    # Get the label with the highest score\n",
        "    max_label = output['labels'][max_index]\n",
        "\n",
        "    # Get the score of the label with the highest score\n",
        "    max_score = output['scores'][max_index]\n",
        "    return [max_label, max_score]\n",
        "\n",
        "manually_marked_df[['deberta_predication_category', 'deberta_predication_category_score']] = manually_marked_df['text'].apply(perform_deberta_classifier).apply(pd.Series)\n",
        "\n",
        "accuracy_class_predict = accuracy_score(manually_marked_df['category'], manually_marked_df['deberta_predication_category'])\n",
        "print(accuracy_class_predict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## why not T5\n",
        "### T5 is not supported in zero-shot classification pipeline because it does not have a sequence classification head. With T5 the seq classification problem is formulated as text-to-text generation problem which is not possible to support in this zero-shot pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# deberta-v3-large-zeroshot\n",
        "\n",
        "deberta_large_classifier = pipeline(\"zero-shot-classification\", model=\"sileod/deberta-v3-base-tasksource-nli\")\n",
        "\n",
        "\n",
        "def perform_deberta_large_classifier(text):\n",
        "    output = deberta_large_classifier(preprocess_text(text), candidate_labels)\n",
        "    # Find the index of the label with the highest score\n",
        "    max_index = output['scores'].index(max(output['scores']))\n",
        "\n",
        "    # Get the label with the highest score\n",
        "    max_label = output['labels'][max_index]\n",
        "\n",
        "    # Get the score of the label with the highest score\n",
        "    max_score = output['scores'][max_index]\n",
        "    return [max_label, max_score]\n",
        "\n",
        "manually_marked_df[['deberta_large_predication_category', 'deberta_large_predication_category_score']] = manually_marked_df['text'].apply(perform_deberta_large_classifier).apply(pd.Series)\n",
        "\n",
        "accuracy_class_predict = accuracy_score(manually_marked_df['category'], manually_marked_df['deberta_large_predication_category'])\n",
        "print(accuracy_class_predict)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02d2aed797dc441483d8803d8d74f6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a98ee1f2984431bc317acd113a1fca",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f57e89cb93fe4966883324e21c524829",
            "value": 49
          }
        },
        "089c8f0ba9354a7bb2dbc41634ac7d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e7cb24f6ae44433994b2f70bb1a89dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1036bff4d8c148f8890d7183283f28e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a155879a0e4d33abc9c2c4951c0c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_927b5da4fc524ddd90dd200919210b25",
              "IPY_MODEL_9bc31f6b126a4483be56f2d083fc6760",
              "IPY_MODEL_1b6fd4e2b17b4535b58dc6482f1ff9ca"
            ],
            "layout": "IPY_MODEL_a1cff6262f4c43bd9b626f40d53fe3ef"
          }
        },
        "1b6fd4e2b17b4535b58dc6482f1ff9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3802c5b12e834eb39cf316c2700c879c",
            "placeholder": "",
            "style": "IPY_MODEL_579e5a8a96c246cdb941335f82a52fb8",
            "value": "112/112[00:00&lt;00:00,1.59kB/s]"
          }
        },
        "2bd73e17a8ef48b6a0063b153d9006c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30a98ee1f2984431bc317acd113a1fca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "324ac8fa62894f75aef9ccaeb6159938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "344b21f271114f6aa3e956a1dfaefe38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37629a02aa1d4d72bd24bfa1c0a30918": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3802c5b12e834eb39cf316c2700c879c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e45ae9fb3d84202a6fcfd3317499f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44325d6b91764d67a7f90c68aced716f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c084639238a45a9a4586a0b05283e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51536207c7c143258398fd03787ec2f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568c73553b8648d4b74391b87838a76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5696db505896423abac4bc785e6fce9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_823fad1bda224288bc6786e3ea4179a1",
            "placeholder": "",
            "style": "IPY_MODEL_72db37f4834d4c1fa50ad7b249732b70",
            "value": "433M/433M[00:07&lt;00:00,68.5MB/s]"
          }
        },
        "56ad8bfdcb1a45c2a65352c8a499eef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683e085695ae4a05a40e70bc85159fe3",
            "placeholder": "",
            "style": "IPY_MODEL_3e45ae9fb3d84202a6fcfd3317499f1d",
            "value": "tokenizer_config.json:100%"
          }
        },
        "579e5a8a96c246cdb941335f82a52fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63dfd85fc4064215b20fc35217ff313c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f11bb9e9370a403bbe639be12f6703b9",
              "IPY_MODEL_648f875e21d84549a47dfbe95e51ac47",
              "IPY_MODEL_ee22eeec775545ce897642c2b62edea2"
            ],
            "layout": "IPY_MODEL_6b610b456e81425485e100c1ecac371c"
          }
        },
        "648f875e21d84549a47dfbe95e51ac47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e817cf68f93142bfb356ce2478c10ab2",
            "max": 746,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4a44ad925d1462298b9004f2e58eda4",
            "value": 746
          }
        },
        "683e085695ae4a05a40e70bc85159fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b610b456e81425485e100c1ecac371c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72db37f4834d4c1fa50ad7b249732b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73061ad5f1c24d3284d5f4890a1cf1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da1e2c25eb5448e9dc757c98d6539a2",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44325d6b91764d67a7f90c68aced716f",
            "value": 213450
          }
        },
        "7da1e2c25eb5448e9dc757c98d6539a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb3c099243648c39ce21e89d263108b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81218cae9b114deda5efe67ebccd4ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8122605946c64cf1b80e18da16b62d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51536207c7c143258398fd03787ec2f5",
            "placeholder": "",
            "style": "IPY_MODEL_2bd73e17a8ef48b6a0063b153d9006c6",
            "value": "213k/213k[00:00&lt;00:00,1.40MB/s]"
          }
        },
        "823fad1bda224288bc6786e3ea4179a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895bdab903f143fab9075ab9b769d8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f415836ab440bdb84300fa5a09981c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c79d5c615fd4f2f84a73e14a8700eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "927b5da4fc524ddd90dd200919210b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1036bff4d8c148f8890d7183283f28e7",
            "placeholder": "",
            "style": "IPY_MODEL_e3dddd82bf5648ec8eba1caf1b5547e3",
            "value": "special_tokens_map.json:100%"
          }
        },
        "9bc31f6b126a4483be56f2d083fc6760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7cb24f6ae44433994b2f70bb1a89dd",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6a177d7a89f41abbfbf2ea5906c9e31",
            "value": 112
          }
        },
        "a1cff6262f4c43bd9b626f40d53fe3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a177d7a89f41abbfbf2ea5906c9e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a902df1d223f41d39fb09016c95d5e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcf8afc483284445966ba610e6d06619",
              "IPY_MODEL_73061ad5f1c24d3284d5f4890a1cf1c4",
              "IPY_MODEL_8122605946c64cf1b80e18da16b62d1c"
            ],
            "layout": "IPY_MODEL_8c79d5c615fd4f2f84a73e14a8700eb6"
          }
        },
        "b69128b2082a4a52b3be4aa440c41d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fb3c099243648c39ce21e89d263108b",
            "placeholder": "",
            "style": "IPY_MODEL_089c8f0ba9354a7bb2dbc41634ac7d27",
            "value": "model.safetensors:100%"
          }
        },
        "bee4c831970845eb92d8c6471d4b8557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2fff18a17c448c8b8b4fcf341c5304",
            "placeholder": "",
            "style": "IPY_MODEL_568c73553b8648d4b74391b87838a76d",
            "value": "49.0/49.0[00:00&lt;00:00,1.10kB/s]"
          }
        },
        "cabbc666f18a4ee8bfd6bf7be7863450": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf33926ec7b84d5b866859868c56b0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8f4b4c6fe80481b8766d2414a201cd3",
            "max": 433279996,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c084639238a45a9a4586a0b05283e1b",
            "value": 433279996
          }
        },
        "dd2fff18a17c448c8b8b4fcf341c5304": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3dddd82bf5648ec8eba1caf1b5547e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4a44ad925d1462298b9004f2e58eda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5a944b5ea9d45a0942502e0900cbf0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b69128b2082a4a52b3be4aa440c41d74",
              "IPY_MODEL_cf33926ec7b84d5b866859868c56b0e1",
              "IPY_MODEL_5696db505896423abac4bc785e6fce9c"
            ],
            "layout": "IPY_MODEL_f13d4ebadc8f4b60bf35c2e03a874161"
          }
        },
        "e817cf68f93142bfb356ce2478c10ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f4b4c6fe80481b8766d2414a201cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee22eeec775545ce897642c2b62edea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cabbc666f18a4ee8bfd6bf7be7863450",
            "placeholder": "",
            "style": "IPY_MODEL_81218cae9b114deda5efe67ebccd4ffa",
            "value": "746/746[00:00&lt;00:00,25.6kB/s]"
          }
        },
        "f062f290acf04744b36cc4c92be6809b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56ad8bfdcb1a45c2a65352c8a499eef5",
              "IPY_MODEL_02d2aed797dc441483d8803d8d74f6db",
              "IPY_MODEL_bee4c831970845eb92d8c6471d4b8557"
            ],
            "layout": "IPY_MODEL_89f415836ab440bdb84300fa5a09981c"
          }
        },
        "f11bb9e9370a403bbe639be12f6703b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37629a02aa1d4d72bd24bfa1c0a30918",
            "placeholder": "",
            "style": "IPY_MODEL_324ac8fa62894f75aef9ccaeb6159938",
            "value": "config.json:100%"
          }
        },
        "f13d4ebadc8f4b60bf35c2e03a874161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57e89cb93fe4966883324e21c524829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcf8afc483284445966ba610e6d06619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_895bdab903f143fab9075ab9b769d8ab",
            "placeholder": "",
            "style": "IPY_MODEL_344b21f271114f6aa3e956a1dfaefe38",
            "value": "vocab.txt:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
